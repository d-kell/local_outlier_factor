{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "* Added two new methods: LOF novelty detection and isolation_forest\n",
    "* All results are from cross_val_score(pls) using the validation set with outliers removed\n",
    "* Methods have the following patterns:\n",
    "    * LOF_outlier_detection\n",
    "        * clf.fit_predict(X_validation) -> outlier_indices\n",
    "        * df_val.drop(outlier_indices)\n",
    "        * cross_val_score(PLS, df_val.dropped)\n",
    "    * LOF_novelty_detection\n",
    "        * clf.fit(X_train)\n",
    "        * clf.predict(X_validation) -> outlier_indices\n",
    "        * df_val.drop(outlier_indices)\n",
    "        * cross_val_score(PLS, df_val.dropped)\n",
    "    * isolation_forest\n",
    "        * clf.fit(X_train)\n",
    "        * clf.predict(X_validation) -> outlier_indices\n",
    "        * df_val.drop(outlier_indices)\n",
    "        * cross_val_score(PLS, df_val.dropped)\n",
    "    * PCA_outliers / PCA_scoring\n",
    "        * PCA_outliers(X_validation) -> outlier_indices\n",
    "        * df_val.drop(outlier_indices)\n",
    "        * cross_val_score(PLS, df_val.dropped)\n",
    "\n",
    "#### Note:\n",
    "* Function signatures are misleading, most parameters are not used (only need X_train, X_val,a nd df_val). Noticed this late and did not have time to clean up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as ststc\n",
    "import scipy.stats as st\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('../agora')\n",
    "import agora_lib\n",
    "from agora_lib import plotting\n",
    "from agora_lib import prep\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(path, column_drop_list):\n",
    "    \"\"\"Takes an excel file, sets first column as index, drops columns according to column drop_list parameter,\n",
    "    scales the data with StandardScaler, drops empty rows. Returns a scaled dataframe with only target and spectra.\"\"\"\n",
    "    path = path\n",
    "    xls = pd.ExcelFile(path)\n",
    "    df = xls.parse()\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    df_dropped = df.drop(column_drop_list, axis=1)\n",
    "    df_dropped.dropna()\n",
    "    ndarray_SS = StandardScaler().fit_transform(df_dropped)\n",
    "    df_dropped_SS = pd.DataFrame(ndarray_SS)\n",
    "    df_dropped_SS.dropna(inplace=True)\n",
    "    return df_dropped_SS\n",
    "\n",
    "def data_processing_parse(path):\n",
    "    \"\"\"Same as data_processing, but deals with multi-tab formatted excel (per standard Agora submission)\"\"\"\n",
    "    xls = pd.ExcelFile(path)\n",
    "    Y_df = xls.parse(sheet_name='Reference Data (Y)')\n",
    "    X_df = xls.parse(sheet_name='Raw Spectra (X)')\n",
    "    Y_df.set_index(Y_df.columns[0], inplace=True)\n",
    "    X_df.set_index(X_df.columns[0], inplace=True)\n",
    "    df_concat = pd.concat([Y_df, X_df], axis=1)\n",
    "    df_concat_nd = StandardScaler().fit_transform(df_concat)\n",
    "    df_concat_df = pd.DataFrame(df_concat_nd)\n",
    "    df_concat_df.dropna(inplace=True)\n",
    "    return df_concat_df\n",
    "\n",
    "def frame_parse(df):\n",
    "    X = df.iloc[:, 1:]\n",
    "    Y = df.iloc[:, 0]\n",
    "    return X, Y\n",
    "\n",
    "def data_splitter(df):\n",
    "    X = df.iloc[:, 1:]\n",
    "    Y = df.iloc[:, 0]\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X, Y, test_size=0.20)\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "    return X_train, X_dev, y_train, y_dev, df_train\n",
    "\n",
    "#Stand alone sav_gol filter\n",
    "def sav_gol_filter(df):\n",
    "    #work out later\n",
    "    return df\n",
    "\n",
    "#Stand alone scaler (some datasets already scaled)\n",
    "def Standard_scale_df(df):\n",
    "    #work out later\n",
    "    return df\n",
    "\n",
    "def LOF_outlier_detection(X_train, X_val, y_train, y_val, df_val, range_neighbors):\n",
    "    list_num_outliers_dropped = []\n",
    "    list_r2_val_set = []\n",
    "    list_temp_mse_scores = []\n",
    "    list_neg_mse_val_set = []\n",
    "    list_pos_mse_val_set = []\n",
    "    dict_return = {}\n",
    "    for n in range_neighbors:\n",
    "        #initiate the LOF classifier with num_neighbors per the loop\n",
    "        clf = LocalOutlierFactor(n_neighbors=n)\n",
    "        #use fit_predict(X_train) for straight-forward outlier detection\n",
    "        LOF_outlier_flags = clf.fit_predict(X_val)\n",
    "        #get a list of outliers and use it to drop rows from df_train\n",
    "        lst_outl_indices = [i for i,item in enumerate(LOF_outlier_flags) if item < 0]\n",
    "        list_num_outliers_dropped.append(len(lst_outl_indices))\n",
    "        #drop outliers from the validation dataframe\n",
    "        df_drop = df_val.drop(df_val.index[lst_outl_indices])\n",
    "        X_pls = df_drop.iloc[:,1:]\n",
    "        y_pls = df_drop.iloc[:,0]\n",
    "        #fit the pls the training partition without outliers\n",
    "        pls1 = PLSRegression(n_components=5)\n",
    "        r2_score_val_set = np.mean(cross_val_score(pls1, X_pls, y_pls, cv=5, scoring='r2', n_jobs=-1))\n",
    "        list_r2_val_set.append(r2_score_val_set)\n",
    "        list_temp_mse_scores = cross_val_score(pls1, X_pls, y_pls, cv=5, scoring='neg_mean_squared_error',\n",
    "                                                      n_jobs=-1)\n",
    "        list_neg_mse_val_set.append(np.mean(list_temp_mse_scores))\n",
    "        list_pos_mse_val_set.append(np.mean([-1*x for x in list_temp_mse_scores]))\n",
    "\n",
    "        dict_return = {'num_neighbors':range_neighbors, 'num_outliers_dropped':list_num_outliers_dropped,\n",
    "                        'r2_CV_score_validation': list_r2_val_set,\n",
    "                        'mse_CV_score_validation': list_pos_mse_val_set}\n",
    "    return dict_return\n",
    "\n",
    "def LOF_novelty_detection(X_train, X_val, y_train, y_val, df_val, range_neighbors):\n",
    "    list_num_outliers_dropped = []\n",
    "    list_r2_val_set = []\n",
    "    list_temp_mse_scores = []\n",
    "    list_neg_mse_val_set = []\n",
    "    list_pos_mse_val_set = []\n",
    "    dict_return = {}\n",
    "    for n in range_neighbors:\n",
    "        #initiate the LOF classifier with num_neighbors per the loop; novelty=True for nov detection\n",
    "        clf = LocalOutlierFactor(n_neighbors=n, novelty=True)\n",
    "        #train the LOF on X_train\n",
    "        clf.fit(X_train)\n",
    "        LOF_outlier_flags = clf.predict(X_val)\n",
    "        #get a list of outliers and use it to drop rows from df_train\n",
    "        lst_outl_indices = [i for i,item in enumerate(LOF_outlier_flags) if item < 0]\n",
    "        list_num_outliers_dropped.append(len(lst_outl_indices))\n",
    "        #drop outliers from the validation dataframe\n",
    "        df_drop = df_val.drop(df_val.index[lst_outl_indices])\n",
    "        X_pls = df_drop.iloc[:,1:]\n",
    "        y_pls = df_drop.iloc[:,0]\n",
    "        #fit the pls the training partition without outliers\n",
    "        pls1 = PLSRegression(n_components=5)\n",
    "        r2_score_val_set = np.mean(cross_val_score(pls1, X_pls, y_pls, cv=5, scoring='r2', n_jobs=-1))\n",
    "        list_r2_val_set.append(r2_score_val_set)\n",
    "        list_temp_mse_scores = cross_val_score(pls1, X_pls, y_pls, cv=5, scoring='neg_mean_squared_error',\n",
    "                                                      n_jobs=-1)\n",
    "        list_neg_mse_val_set.append(np.mean(list_temp_mse_scores))\n",
    "        list_pos_mse_val_set.append(np.mean([-1*x for x in list_temp_mse_scores]))\n",
    "\n",
    "        dict_return = {'num_neighbors':range_neighbors, 'num_outliers_dropped':list_num_outliers_dropped,\n",
    "                        'r2_CV_score_validation': list_r2_val_set,\n",
    "                        'mse_CV_score_validation': list_pos_mse_val_set}\n",
    "    return dict_return\n",
    "\n",
    "def isolation_forest(X_train, X_val, y_train, y_val, df_val, range_estimators):\n",
    "    list_num_outliers_dropped = []\n",
    "    list_r2_val_set = []\n",
    "    list_temp_mse_scores = []\n",
    "    list_neg_mse_val_set = []\n",
    "    list_pos_mse_val_set = []\n",
    "    dict_return = {}\n",
    "    for n in range_estimators:\n",
    "        #initiate the isolation forest\n",
    "        clf = IsolationForest(n_estimators=n)\n",
    "        clf.fit(X_train)\n",
    "        forest_outlier_flags = clf.predict(X_val)\n",
    "        #get a list of outliers and use it to drop rows from df_train\n",
    "        lst_outl_indices = [i for i,item in enumerate(forest_outlier_flags) if item < 0]\n",
    "        list_num_outliers_dropped.append(len(lst_outl_indices))\n",
    "        #drop outliers from the validation dataframe\n",
    "        df_drop = df_val.drop(df_val.index[lst_outl_indices])\n",
    "        X_pls = df_drop.iloc[:,1:]\n",
    "        y_pls = df_drop.iloc[:,0]\n",
    "        #fit the pls the training partition without outliers\n",
    "        pls1 = PLSRegression(n_components=5)\n",
    "        r2_score_val_set = np.mean(cross_val_score(pls1, X_pls, y_pls, cv=5, scoring='r2', n_jobs=-1))\n",
    "        list_r2_val_set.append(r2_score_val_set)\n",
    "        list_temp_mse_scores = cross_val_score(pls1, X_pls, y_pls, cv=5, scoring='neg_mean_squared_error',\n",
    "                                                      n_jobs=-1)\n",
    "        list_neg_mse_val_set.append(np.mean(list_temp_mse_scores))\n",
    "        list_pos_mse_val_set.append(np.mean([-1*x for x in list_temp_mse_scores]))\n",
    "\n",
    "        dict_return = {'num_neighbors':range_estimators, 'num_outliers_dropped':list_num_outliers_dropped,\n",
    "                        'r2_CV_score_validation': list_r2_val_set,\n",
    "                        'mse_CV_score_validation': list_pos_mse_val_set}\n",
    "    return dict_return\n",
    "\n",
    "def PCA_outliers(X_df):\n",
    "    list_of_list_outliers = []\n",
    "    x_df_index = X_df.index.values.tolist()\n",
    "    #Set up principal component DataFrame - use only spectra\n",
    "    pca = PCA(n_components=6)\n",
    "    principalComponents = pca.fit_transform(X_df)\n",
    "    principalDf = pd.DataFrame(data=principalComponents, columns=['principal component 1', 'principal component 2',\n",
    "                                                                  'principal component 3', 'principal component 4',\n",
    "                                                                  'principal component 5', 'principal component 6'])\n",
    "    # run calculate_distances() on the main principal df for the PC1 vs PC2 combination\n",
    "    principalDf = prep.calculate_distances(principalDf,\"Distance: PC1&PC2\", \"principal component 1\",\n",
    "                                 \"principal component 2\")\n",
    "    # use the best_fit_distribution method to calculate the p-value on the distances between PCs\n",
    "    best_fit_name_1_2, best_fit_params_1_2, best_fit_int_1_2 = plotting.best_fit_distribution(principalDf[\"Distance: PC1&PC2\"], 200)\n",
    "    index_list_PC1_2 = []\n",
    "    for i in range(len(principalDf)):\n",
    "        if principalDf.loc[i, \"Distance: PC1&PC2\"] > best_fit_int_1_2[1]:\n",
    "            index_list_PC1_2.append(i)\n",
    "    list_of_list_outliers.append(index_list_PC1_2)\n",
    "    \n",
    "    principalDf = prep.calculate_distances(principalDf,\"Distance: PC3&PC4\", \"principal component 3\",\n",
    "                                 \"principal component 4\")\n",
    "    # use the best_fit_distribution method to calculate the p-value on the distances between PCs\n",
    "    best_fit_name_3_4, best_fit_params_3_4, best_fit_int_3_4 = plotting.best_fit_distribution(principalDf[\"Distance: PC3&PC4\"], 200)\n",
    "    index_list_PC3_4 = []\n",
    "    for i in range(len(principalDf)):\n",
    "        if principalDf.loc[i, \"Distance: PC3&PC4\"] > best_fit_int_3_4[1]:\n",
    "            index_list_PC3_4.append(i)\n",
    "    list_of_list_outliers.append(index_list_PC3_4)\n",
    "    \n",
    "    principalDf = prep.calculate_distances(principalDf,\"Distance: PC5&PC6\", \"principal component 5\",\n",
    "                                 \"principal component 6\")\n",
    "    # use the best_fit_distribution method to calculate the p-value on the distances between PCs\n",
    "    best_fit_name_5_6, best_fit_params_5_6, best_fit_int_5_6 = plotting.best_fit_distribution(principalDf[\"Distance: PC5&PC6\"], 200)\n",
    "    index_list_PC5_6 = []\n",
    "    for i in range(len(principalDf)):\n",
    "        if principalDf.loc[i, \"Distance: PC5&PC6\"] > best_fit_int_5_6[1]:\n",
    "            index_list_PC5_6.append(i)\n",
    "    list_of_list_outliers.append(index_list_PC5_6)\n",
    "\n",
    "    return list_of_list_outliers\n",
    "\n",
    "def PCA_scoring(list_of_list_outliers, X_val, y_val, df_val):\n",
    "    list_PCA_combo = ['PC1&PC2', 'PC3&PC4', 'PC5&PC6']\n",
    "    list_num_outliers_dropped = []\n",
    "    lst_of_PCA_dfs = []\n",
    "    list_temp_mse_scores = []\n",
    "    list_neg_mse_test = []\n",
    "    list_pos_mse_test = []\n",
    "    list_r2_test = []\n",
    "   \n",
    "    dict_return = {}\n",
    "    for lst_indices in list_of_list_outliers:\n",
    "        df_dropped = df_val.drop(df_val.index[lst_indices]) \n",
    "        lst_of_PCA_dfs.append(df_dropped)\n",
    "        list_num_outliers_dropped.append(len(lst_indices))\n",
    "    for df in lst_of_PCA_dfs:\n",
    "        X_pls = df.iloc[:,1:]\n",
    "        y_pls = df.iloc[:,0]\n",
    "        pls1 = PLSRegression(n_components=5)\n",
    "        list_temp_mse_scores = cross_val_score(pls1, X_pls, y_pls, cv=5, scoring='neg_mean_squared_error',\n",
    "                                                      n_jobs=-1)\n",
    "        list_neg_mse_test.append(np.mean(list_temp_mse_scores))\n",
    "        list_pos_mse_test.append(np.mean([-1*x for x in list_temp_mse_scores]))\n",
    "        list_r2_test.append(np.mean(cross_val_score(pls1, X_pls, y_pls, cv=5, scoring='r2', n_jobs=-1)))\n",
    "\n",
    "    dict_return = {'PCA combo':list_PCA_combo, 'num_outliers_dropped':list_num_outliers_dropped,\n",
    "                        'r2_CV_score_validation': list_r2_test,\n",
    "                        'mse_CV_score_validation': list_pos_mse_test}\n",
    "    return dict_return    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe columns to be dropped for data_processing()\n",
    "list_proteinDf_drop_columns_train = ['pH (measured)', 'Osmo  (measured)', 'PS20 (measured)','Met (measured)'\n",
    "                            ,'pH (target)', 'Protein Concentration  (target)', 'PS20 (target)','Met (target)']\n",
    "list_osmoDf_drop_columns_train = ['pH (measured)', 'Protein Concentration  (measured)', 'PS20 (measured)','Met (measured)'\n",
    "                            ,'pH (target)', 'Protein Concentration  (target)', 'PS20 (target)','Met (target)']\n",
    "\n",
    "list_proteinDf_drop_columns_val = ['pH (measured)', 'Osmo  (measured)', 'PS20 (measured)','Met (measured)']\n",
    "list_osmoDf_drop_columns_val = ['pH (measured)', 'Protein Concentration  (measured)', 'PS20 (measured)','Met (measured)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"Formulation_DOE_Merged_Data_design_targets_v2.xlsx\"\n",
    "path_val = \"Mock_Validation_Dataset.xlsx\"\n",
    "\n",
    "path_gluc_train = \"Agora_Submission_Glucose_Val.xlsx\"\n",
    "path_gluc_val = \"Agora_Submission_Glucose_ValSet.xlsx\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Formulation_DOE_Merged_Data_design_targets_v2.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f81ce388733b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#datasets needing complumns removed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_protein_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_proteinDf_drop_columns_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_protein_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_proteinDf_drop_columns_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_osmo_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_osmoDf_drop_columns_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_osmo_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_osmoDf_drop_columns_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4aceb2d76e2d>\u001b[0m in \u001b[0;36mdata_processing\u001b[0;34m(path, column_drop_list)\u001b[0m\n\u001b[1;32m      3\u001b[0m     scales the data with StandardScaler, drops empty rows. Returns a scaled dataframe with only target and spectra.\"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mxls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Formulation_DOE_Merged_Data_design_targets_v2.xlsx'"
     ]
    }
   ],
   "source": [
    "#datasets needing complumns removed\n",
    "df_protein_train = data_processing(path_train, list_proteinDf_drop_columns_train)\n",
    "df_protein_val = data_processing(path_val, list_proteinDf_drop_columns_val)\n",
    "df_osmo_train = data_processing(path_train, list_osmoDf_drop_columns_train)\n",
    "df_osmo_val = data_processing(path_val, list_osmoDf_drop_columns_val)\n",
    "#datasets parsed per sheet\n",
    "df_glucose_train = data_processing_parse(path_gluc_train)\n",
    "df_glucose_val = data_processing_parse(path_gluc_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_protein_osmo_train = [20,40,60,80,100]\n",
    "X_protein_train, y_protein_train = frame_parse(df_protein_train)\n",
    "X_protein_val, y_protein_val = frame_parse(df_protein_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF outlier detection method\n",
    "dict_return_protein_OD = LOF_outlier_detection(X_protein_train, X_protein_val, y_protein_train, y_protein_val, \n",
    "                                  df_protein_val, range_protein_osmo_train) \n",
    "print(\"LOF Outlier Detection Method - Formulation DOE Protein target\")\n",
    "protein_display_OD = pd.DataFrame(dict_return_protein_OD)\n",
    "protein_display_OD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF novelty detection method\n",
    "dict_return_protein_nov = LOF_novelty_detection(X_protein_train, X_protein_val, y_protein_train, y_protein_val, \n",
    "                                  df_protein_val, range_protein_osmo_train) \n",
    "print(\"LOF Novelty Detection Method - Formulation DOE Protein target\")\n",
    "protein_display_nov = pd.DataFrame(dict_return_protein_nov)\n",
    "protein_display_nov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolation Forest detection method\n",
    "dict_return_protein_IF = isolation_forest(X_protein_train, X_protein_val, y_protein_train, y_protein_val, \n",
    "                                  df_protein_val, range_protein_osmo_train) \n",
    "print(\"Isolation Forest Outlier Detection Method - Formulation DOE Protein target\")\n",
    "protein_display_IF = pd.DataFrame(dict_return_protein_IF)\n",
    "protein_display_IF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare to PCA\n",
    "list_protein_PCA_outliers = PCA_outliers(X_protein_train)\n",
    "dict_return_protein_PCA = PCA_scoring(list_protein_PCA_outliers, X_protein_val, y_protein_val, df_protein_train)\n",
    "protein_display_PCA = pd.DataFrame(dict_return_protein_PCA)\n",
    "protein_display_PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = range_protein_osmo_train\n",
    "plt.title(\"r2 score for PLS on Formulation DOE Protein target validation set (no outliers)\", fontweight=\"bold\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"r2 Score\")\n",
    "plt.ylim(0.80, 0.98)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, protein_display_OD['r2_CV_score_validation'], label=\"LOF_outlier_detection\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, protein_display_nov['r2_CV_score_validation'], label=\"LOF_novelty_detection\",\n",
    "             color=\"red\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, protein_display_IF['r2_CV_score_validation'], label=\"Isolation_Forest_detection\",\n",
    "             color=\"m\", lw=lw)\n",
    "\n",
    "#PC1 v PC2 score\n",
    "plt.hlines(protein_display_PCA.loc[0, 'r2_CV_score_validation'],param_range[0], param_range[-1], color='g', \n",
    "           linestyle=':', label=\"PCA_1&2_r2 (val set)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = range_protein_osmo_train\n",
    "plt.title(\"MSE for PLS on Formulation DOE Protein target validation set (no outliers)\", fontweight=\"bold\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim(0.01, 0.05)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, protein_display_OD['mse_CV_score_validation'], label=\"LOF_outlier_detection\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, protein_display_nov['mse_CV_score_validation'], label=\"LOF_novelty_detection\",\n",
    "             color=\"red\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, protein_display_IF['mse_CV_score_validation'], label=\"Isolation_Forest_detection\",\n",
    "             color=\"m\", lw=lw)\n",
    "\n",
    "#PC1 v PC2 score\n",
    "plt.hlines(protein_display_PCA.loc[0, 'mse_CV_score_validation'],param_range[0], param_range[-1], color='g', \n",
    "           linestyle=':', label=\"PCA_1&2_r2 (val set)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_protein_osmo_train = [20,40,60,80,100]\n",
    "X_osmo_train, y_osmo_train = frame_parse(df_osmo_train)\n",
    "X_osmo_val, y_osmo_val = frame_parse(df_osmo_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF outlier detection method\n",
    "dict_return_osmo_OD = LOF_outlier_detection(X_osmo_train, X_osmo_val, y_osmo_train, y_osmo_val, \n",
    "                                  df_osmo_val, range_protein_osmo_train) \n",
    "\n",
    "print(\"LOF Outlier Detection Method - Formulation DOE Osmo target\")\n",
    "osmo_display_OD = pd.DataFrame(dict_return_osmo_OD)\n",
    "osmo_display_OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF novelty detection method\n",
    "dict_return_osmo_nov = LOF_novelty_detection(X_osmo_train, X_osmo_val, y_osmo_train, y_osmo_val, \n",
    "                                  df_osmo_val, range_protein_osmo_train) \n",
    "\n",
    "print(\"LOF Novelty Detection Method - Formulation DOE Osmo target\")\n",
    "osmo_display_nov = pd.DataFrame(dict_return_osmo_nov)\n",
    "osmo_display_nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolation Forest detection method\n",
    "dict_return_osmo_IF = isolation_forest(X_osmo_train, X_osmo_val, y_osmo_train, y_osmo_val, \n",
    "                                  df_osmo_val, range_protein_osmo_train) \n",
    "\n",
    "print(\"Isolation Forest Outlier Detection Method - Formulation DOE Osmo target\")\n",
    "osmo_display_IF = pd.DataFrame(dict_return_osmo_IF)\n",
    "osmo_display_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare to PCA\n",
    "list_osmo_PCA_outliers = PCA_outliers(X_osmo_val)\n",
    "dict_return_osmo_PCA = PCA_scoring(list_osmo_PCA_outliers, X_osmo_val, y_osmo_val, df_osmo_val)\n",
    "\n",
    "print(\"PCA Outlier Detection Method - Formulation DOE Protein target\")\n",
    "osmo_display_PCA = pd.DataFrame(dict_return_osmo_PCA)\n",
    "osmo_display_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = range_protein_osmo_train\n",
    "plt.title(\"r2 score for PLS on Formulation DOE Osmo target validation set (no outliers)\", fontweight=\"bold\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"r2 Score\")\n",
    "plt.ylim(0.80, 0.98)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, osmo_display_OD['r2_CV_score_validation'], label=\"LOF_outlier_detection\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, osmo_display_nov['r2_CV_score_validation'], label=\"LOF_novelty_detection\",\n",
    "             color=\"red\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, osmo_display_IF['r2_CV_score_validation'], label=\"Isolation_Forest_detection\",\n",
    "             color=\"m\", lw=lw)\n",
    "\n",
    "#PC1 v PC2 score\n",
    "plt.hlines(osmo_display_PCA.loc[0, 'r2_CV_score_validation'],param_range[0], param_range[-1], color='g', \n",
    "           linestyle=':', label=\"PCA_1&2_r2 (val set)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = range_protein_osmo_train\n",
    "plt.title(\"MSE for PLS on Formulation DOE Osmo target validation set (no outliers)\", fontweight=\"bold\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim(0.01, 0.06)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, osmo_display_OD['mse_CV_score_validation'], label=\"LOF_outlier_detection\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, osmo_display_nov['mse_CV_score_validation'], label=\"LOF_novelty_detection\",\n",
    "             color=\"red\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, osmo_display_IF['mse_CV_score_validation'], label=\"Isolation_Forest_detection\",\n",
    "             color=\"m\", lw=lw)\n",
    "\n",
    "#PC1 v PC2 score\n",
    "plt.hlines(osmo_display_PCA.loc[0, 'mse_CV_score_validation'],param_range[0], param_range[-1], color='g', \n",
    "           linestyle=':', label=\"PCA_1&2_r2 (val set)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_neighbors_gluc_train = [20,40,60,80,100]\n",
    "X_glucose_train, y_glucose_train = frame_parse(df_glucose_train)\n",
    "X_glucose_val, y_glucose_val = frame_parse(df_glucose_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LOF outlier detection method\n",
    "dict_return_glucose_OD = LOF_outlier_detection(X_glucose_train, X_glucose_val, y_glucose_train, y_glucose_val, \n",
    "                                  df_glucose_val, range_neighbors_gluc_train) \n",
    "\n",
    "print(\"LOF Outlier Detection Method - Agora_Submission_Glucose_ValSet\")\n",
    "glucose_display_OD = pd.DataFrame(dict_return_glucose_OD)\n",
    "glucose_display_OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF novelty detection method\n",
    "dict_return_glucose_nov = LOF_novelty_detection(X_glucose_train, X_glucose_val, y_glucose_train, y_glucose_val, \n",
    "                                  df_glucose_val, range_neighbors_gluc_train) \n",
    "\n",
    "print(\"LOF Novelty Detection Method - Agora_Submission_Glucose_ValSet\")\n",
    "glucose_display_nov = pd.DataFrame(dict_return_glucose_nov)\n",
    "glucose_display_nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolation Forest detection method\n",
    "dict_return_glucose_IF = isolation_forest(X_glucose_train, X_glucose_val, y_glucose_train, y_glucose_val, \n",
    "                                  df_glucose_val, range_neighbors_gluc_train) \n",
    "\n",
    "print(\"Isolation Forest Outlier Detection Method - Agora_Submission_Glucose_ValSet\")\n",
    "glucose_display_IF = pd.DataFrame(dict_return_glucose_IF)\n",
    "glucose_display_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare to PCA\n",
    "list_glucose_PCA_outliers = PCA_outliers(X_glucose_val)\n",
    "dict_return_glucose_PCA = PCA_scoring(list_glucose_PCA_outliers, X_glucose_val, y_glucose_val, df_glucose_val)\n",
    "\n",
    "print(\"PCA Outlier Detection Method - Agora_Submission_Glucose_ValSet\")\n",
    "glucose_display_PCA = pd.DataFrame(dict_return_glucose_PCA)\n",
    "glucose_display_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = range_neighbors_gluc_train\n",
    "plt.title(\"r2 score for PLS on Agora_Submission_Glucose_ValSet (no outliers)\", fontweight=\"bold\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"r2 Score\")\n",
    "plt.ylim(0.20, 0.75)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, glucose_display_OD['r2_CV_score_validation'], label=\"LOF_outlier_detection\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, glucose_display_nov['r2_CV_score_validation'], label=\"LOF_novelty_detection\",\n",
    "             color=\"red\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, glucose_display_IF['r2_CV_score_validation'], label=\"Isolation_Forest_detection\",\n",
    "             color=\"m\", lw=lw)\n",
    "\n",
    "#PC1 v PC2 score\n",
    "plt.hlines(glucose_display_PCA.loc[0, 'r2_CV_score_validation'],param_range[0], param_range[-1], color='g', \n",
    "           linestyle=':', label=\"PCA_1&2_r2 (val set)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = range_neighbors_gluc_train\n",
    "plt.title(\"MSE for PLS on Agora_Submission_Glucose_ValSet (no outliers)\", fontweight=\"bold\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim(0.20, 0.45)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, glucose_display_OD['mse_CV_score_validation'], label=\"LOF_outlier_detection\",\n",
    "             color=\"navy\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, glucose_display_nov['mse_CV_score_validation'], label=\"LOF_novelty_detection\",\n",
    "             color=\"red\", lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, glucose_display_IF['mse_CV_score_validation'], label=\"Isolation_Forest_detection\",\n",
    "             color=\"m\", lw=lw)\n",
    "\n",
    "#PC1 v PC2 score\n",
    "plt.hlines(glucose_display_PCA.loc[0, 'mse_CV_score_validation'],param_range[0], param_range[-1], color='g', \n",
    "           linestyle=':', label=\"PCA_1&2_r2 (val set)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
